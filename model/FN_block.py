'''
Use this block to learn the fourier coefficients from the input image wich is used to regress the tokens of the image generated by the encoder.
'''
import torch
import torch.nn as nn
import torch.nn.functional as F
from timm.models.vision_transformer import PatchEmbed, Attention
import numpy as np


class res_block_with_label_condition(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, label_dim: int = 256, downsample = None):
        super(res_block_with_label_condition, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) 
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) if downsample is None else \
                    nn.Conv2d(out_channels, out_channels, kernel_size=2, stride=2, padding=0, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        self.stride = stride
        self.label_dim = label_dim
        self.label_emb = nn.Linear(label_dim, out_channels)
    
    def forward(self, x, label):
        identity = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        
        if self.downsample is not None:
            identity = self.downsample(x)
        
        out += identity
        out = self.relu(out)
        
        label = self.label_emb(label)
        out = out * (1 + F.sigmoid(label / label.max()).unsqueeze(-1).unsqueeze(-1))
        
        return out
    

class FN_coefficient(nn.Module):
    '''
    This model uses a resnet like architecture with label conditioning to learn the fourier coefficients of the input image.
    '''
    def __init__(self, input_size: int = 32, 
                 in_channels: int = 4, 
                 num_fourier_terms: int = 256, 
                 num_classes: int = 1000):
        super(FN_coefficient, self).__init__()
        self.input_size = input_size
        self.in_channels = in_channels
        self.num_fourier_terms = num_fourier_terms
        self.num_classes = num_classes
        
        self.label_emb = nn.Embedding(num_classes, 256)
        
        # resnet model
        self.res_block = nn.ModuleList([
            nn.Conv2d(in_channels, 8, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(8),
            nn.ReLU(inplace=True),
        ])
        in_channels, input_size = 8, input_size
        for _ in range(4):
            self.res_block.append(res_block_with_label_condition(in_channels, in_channels, label_dim=256))
            self.res_block.append(res_block_with_label_condition(in_channels, in_channels * 2, 
                                                                 downsample=nn.Conv2d(in_channels, in_channels * 2, kernel_size=2, stride=2, padding=0),
                                                                 label_dim=256))
            in_channels *= 2
            input_size //= 2
        
        # flatten the output and pass it through a linear layer to get the fourier coefficients
        self.fc_xy = nn.Linear(in_channels * input_size * input_size, num_fourier_terms * 2)
        self.fc_yx = nn.Linear(in_channels * input_size * input_size, num_fourier_terms * 2)
        self.flatten = nn.Flatten()
    
    def forward(self, x, label):
        label_emb = self.label_emb(label)
        for layer in self.res_block:
            if isinstance(layer, res_block_with_label_condition):
                x = layer(x, label_emb)
            else:
                x = layer(x)
        x = self.flatten(x)
        x1 = self.fc_xy(x)
        x2 = self.fc_yx(x)
        Axy, Bxy = x1.chunk(2, dim=1)
        Ayx, Byx = x2.chunk(2, dim=1)
        return {"Axy": Axy, "Ayx": Ayx, "Bxy": Bxy, "Byx": Byx}


class FN_coefficients_loss(nn.Module):
    '''
    This loss function is used to separate the fourier coefficients of the input image with different labels.
    Make fourier coefficients of the same label close to each other and those of different labels far from each other.
    Use cosine similarity to calculate the loss to reach the above objective.
    '''
    def __init__(self, num_classes: int = 1000):
        super(FN_coefficients_loss, self).__init__()
        self.num_classes = num_classes
        self.cos = nn.CosineSimilarity(dim=1)
        
    def forward(self, fn_coefficients, labels):
        '''
        fn_coefficients: a dict of tensors of shape (batch_size, num_fourier_terms)
            dict keys: Axy, Bxy, Ayx, Byx, A0
        labels: tensor of shape (batch_size)
        '''
        Axy, Bxy, Ayx, Byx = fn_coefficients['Axy'], fn_coefficients['Bxy'], fn_coefficients['Ayx'], fn_coefficients['Byx']
        loss = 0
        label_set = torch.unique(labels)
        for l in label_set:
            Axy_l, Axy_not_l = Axy[labels == l], Axy[labels != l]
            Bxy_l, Bxy_not_l = Bxy[labels == l], Bxy[labels != l]
            Ayx_l, Ayx_not_l = Ayx[labels == l], Ayx[labels != l]
            Byx_l, Byx_not_l = Byx[labels == l], Byx[labels != l]
            if sum(labels == l) > 1:
                # closer distance between the same label for each fourier coefficient
                loss += 4 - self.cos(Axy_l.unsqueeze(1), Axy_l.unsqueeze(0)).mean() - self.cos(Bxy_l.unsqueeze(1), Bxy_l.unsqueeze(0)).mean() \
                        - self.cos(Ayx_l.unsqueeze(1), Ayx_l.unsqueeze(0)).mean() - self.cos(Byx_l.unsqueeze(1), Byx_l.unsqueeze(0)).mean()
            # farther distance between different labels for each fourier coefficient
            loss += self.cos(Axy_l.unsqueeze(1), Axy_not_l.unsqueeze(0)).mean() + self.cos(Bxy_l.unsqueeze(1), Bxy_not_l.unsqueeze(0)).mean() \
                    + self.cos(Ayx_l.unsqueeze(1), Ayx_not_l.unsqueeze(0)).mean() + self.cos(Byx_l.unsqueeze(1), Byx_not_l.unsqueeze(0)).mean()
        return loss / len(label_set)


def FourierSeries_Reconstruction(An, Bn, num_patch, hidden_size=1024):
    '''
    Reconstruct the image from the Fourier series coefficients.
    An contains {An_x, An_y, An_xy}, Bn contains {Bn_x, Bn_y, Bn_xy}
    An is a dict {"An_xy": An_xy, "An_yx": An_yx}, Bn is a dict {"Bn_xy": Bn_xy, "Bn_yx": Bn_yx}
    where An_xy, An_yx, Bn_xy, Bn_yx are tensors of shape (Batch, N), N is the number of Fourier series terms
    
    img(i, d) = sum(An_yx * cos(2*pi*n*i/num_patch) * sin(2*pi*n*d/hidden_size)) + 
                sum(Bn_yx * sin(2*pi*n*i/num_patch) * cos(2*pi*n*d/hidden_size)) + 
                sum(An_xy * cos(2*pi*n*i/num_patch) * cos(2*pi*n*d/hidden_size)) + 
                sum(Bn_xy * sin(2*pi*n*i/num_patch) * sin(2*pi*n*d/hidden_size))
                   
    d is the channel dimension from 0 to hidden_size, i is the row index of the tokens from 0 to num_patch
    '''
    device = An["Axy"].device
    pi = torch.tensor(3.1415927, device=device, requires_grad=False)
    batch_size, N = An["Axy"].shape
    
    # Precompute cosine and sine terms
    i_indices = torch.arange(num_patch, device=device, requires_grad=False).float()   # (num_patch,)
    d_indices = torch.arange(hidden_size, device=device, requires_grad=False).float()   # (hidden_size,)
    
    cos_i = torch.cos(2 * pi * i_indices[:, None] * torch.arange(N, device=device, requires_grad=False) / num_patch)  # (num_patch, N)
    sin_i = torch.sin(2 * pi * i_indices[:, None] * torch.arange(N, device=device, requires_grad=False) / num_patch)  # (num_patch, N)
    cos_d = torch.cos(2 * pi * d_indices[:, None] * torch.arange(N, device=device, requires_grad=False) / hidden_size)  # (hidden_size, N)
    sin_d = torch.sin(2 * pi * d_indices[:, None] * torch.arange(N, device=device, requires_grad=False) / hidden_size)  # (hidden_size, N)
    
    # Compute components for x, y, and xy
    token_xy = (An["Axy"][:, None, None, :] * cos_i[None, :, None, :] * cos_d[None, None, :, :] +
                Bn["Bxy"][:, None, None, :] * sin_i[None, :, None, :] * sin_d[None, None, :, :]).sum(dim=-1)  # (Batch, num_patch, hidden_size)
    
    token_yx = (An["Ayx"][:, None, None, :] * cos_i[None, :, None, :] * sin_d[None, None, :, :] +
                Bn["Byx"][:, None, None, :] * sin_i[None, :, None, :] * cos_d[None, None, :, :]).sum(dim=-1)  # (Batch, num_patch, hidden_size)
    
    # Combine all components
    img = token_xy + token_yx
    
    return img